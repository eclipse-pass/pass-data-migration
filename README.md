# Introduction 

This project consists of several command line tools designed to export data (objects and binary files) from the first version of PASS,
do a bunch of remediation, and load the data into the new version of PASS.

This is not designed to be a general tool. It is particular to the idiosyncrasies of the first JHU deployment of PASS.

# Package format

A zip consisting of a file objects.ndjson and a directory hierarchy starting at “files” consisting of binary files uploaded by the user. The File objects uri field should contain the full path to the file in the “files” directory. 

The objects.ndjson file will contain PASS objects in newline delimited JSON format. Each line will be a PASS object in JSON-LD format with the following transformations. Each property starting with “@” will have the “@” stripped. The “journalName_suggest” field is removed. (This is to match the design of the original data migration tool and seems reasonable in any case.)

# Export

The export tool retrieves all of the PASS objects from an Elasticsearch index. Each File object also has the binary retrieved which is associated with it in Fedora.

Usage:
```
java -jar target/MigrationExportApp.jar PACKAGE_DIR ELASTIC_SEARCH_URL COOKIE
```

The PACKAGE_DIR is a local directory to write the data in the format above.
The ELASTIC_SEARCH_URL is an Elasticsearch endpoint like https://pass.jhu.edu/es.
The COOKIE is the value retrieved from the Cookie header after going through Shib authentication. If the COOKIE is an empty string then it won't be provided with the requests.

These system properties can be set:
* fcrepo.url:  http://localhost:8080/fcrepo/
* fcrepo.user: user
* fcrepo.pass: xxx

If set they will be used to rewrite fcrepo urls for binaries (useful if the index has a different base hostname for them) and also used for basic auth. 


# Remediation

## Update locator ids

The type identifiers used to construct locator ids on a User have changed. Instead of “hopkins-id” and “jhed”, the locator ids should use “unique-id” and “eppn”.

## Normalize grant awards numbers

The grant award numbers are now being normalized by the grant loader. The exported award numbers must be normalized the same way.

## Delete duplicate objects

There are duplicated objects in PASS production. Duplicates need to be deleted and references updated accordingly. See 
https://docs.google.com/document/d/14lK5XmJ9C4ABBEhYfsM8rnWF5oucx9_RS5fi8t2PwrU/edit#heading=h.5bge4zfb94jp for some thoughts. The existing output from the pass dedupe tool can be ignored. We should be able to just load all the objects in memory and quickly find the duplicates by creating a hashmap keyed by the fields which indicate a duplicate. Duplicates should be deleted and references updated.

## Delete useless objects

There are a handful of File objects with no submission or binary. They should just be removed. 

## Import

Update original tool.

# Original documentation

This project is designed to produce an executable jar to operate on an NDJSON file representing all PASS entities pulled
from a repository. The source repository doesn't matter, but in our case the pull was from an Elasticsearh
index of assets in a Fedora repository. The instructions below in producing the NDJSON file below apply to
this situation - once you have the NDJSON file, operation of the jar should work the same regardless. The target for this
is JSON:API.

## Overview

PASS objects have references to other objects of several types. As creating objects in a new repository may require
that referred-to objects be present in the repository before ingesting the referring objects, some care must be taken in the 
order of ingestion. We address this issue by ordering the ingesting by object type so that referred-to
objects are always present. Since the ids for objects in our source repository were clumsy, we take advantage of
the functionality of the target repository to assign an id when creating an object, and then use the returned
object to map the old id to the new one for each object, to resolve references in the new situation.

The target repository is a JSON:API interface through Elide. The operation of the `JavaUtility` class reflects  the 
requirements constitution conformance with that specification

[The following documentation for Assets is from `pass-test` project.
Yhe file assetsND.json.gz is available at https://github.com/eclipse-pass/pass-test/blob/main/resources/assets/assetsND.json.gz ]
]

## Assets

The file assetsND.json.gz is an NDJSON representation of the
assets taken from our minimal assets Docker image. It contains
some actual assets from production, with users stripped out and
several test users created. The test users have been added in a
way which preserves relationships to some grants, submissions,
etc. so that adding and changing entities and relationships can
be tested.

The NDJSON representation was generated by pulling all of the
entities from a running pass-docker stack index; extracting the
`_source` elements from each of the items in the result array; removing
the `JournalName_suggest` elements from these; adjusting remaining element
names so that they do not begin with `@`.  

The details of the process are as follows:
Bring up the PASS Docker stack. Then, increase the search results window size to at least the number of PASS entities
in the repository. Our test assets image contained 30447 entities, so we set it to 45000:

`curl -XPUT "http://localhost:9200/pass/_settings" -d '{ "index" : { "max_result_window" : 45000 } }' -H "Content-Type: application/json"`

Now we can pull the assets down in a single query, and save it to a file `results.json` :

`curl -X GET "localhost:9200/pass/_search?scroll=1m&size=45000&pretty" -H 'Content-Type: application/json' > results.json
`

Now, clean up the json by picking up the `_source` elements, removing the JournalName_suggest elements, and transforming all attribute names so they don't start with `@`:

`cat results.json | jq '[ .hits.hits[]._source ]' | jq 'del(.. | .journalName_suggest?)' | sed -e 's/\@type/type/g' | sed -e 's/\@id/id/g' | sed -e 's/\@context/context/g'  | jq -c '.[]' > assetsND.json`

## Configuration

Configuration is done through a `.env` file in the directory in which the application is run. The variables to be
set (with defaults in the application) are:

`LOADER_API_HOST= (http://localhost)`
`LOADER_API_PORT= (8080)`
`LOADER_API_NAMESPACE= (data)`

The defaults are what are needed to connect to a locally running `pass-core-main` jar file. The `.env` file just needs to be 
present and readable  (simply `touch`ing the file is enough).

## Invocation

Once the application is configured, invocation is simple - one just needs to supple a path (relative or absolute)
as the sole command line argument. The name of the executable jar will be `NDJsonMigrationApp-<version>.jar`
so an invocation would look something like this:

`java -jar NDJsonMigrationApp-<version>.jar> path to NDJSON data file`

The minimal assets for the JHU demo instance are gzipped here as `assetsND.json.gz`

